{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "extraordinary-ethiopia",
   "metadata": {},
   "source": [
    "# Chapter 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-multiple",
   "metadata": {},
   "source": [
    "# Exercise 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-terry",
   "metadata": {},
   "source": [
    "Embedded Reber grammars were used by Hochreiter and Schmidhuber in their paper about LSTMs. They are artificial grammars that produce strings such as “BPBTSXXVPSEPE.” Check out Jenny Orr’s nice introduction to this topic. Choose a particular embedded Reber grammar (such as the one represented on Jenny Orr’s page), then train an RNN to identify whether a string respects that grammar or not. You will first need to write a function capable of generating a training batch containing about 50% strings that respect the grammar, and 50% that don’t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "challenging-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from random import choice, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "neither-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./reber.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-jumping",
   "metadata": {},
   "source": [
    "## Reber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "desirable-piece",
   "metadata": {},
   "outputs": [],
   "source": [
    "reber_edges = ((0,1,'B'), (1,2,'T'), (1,3,'P'), (2,2,'S'), (2,4,'X'), (3,3,'T'), (3,5,'V'), (4,3,'X'), (4,6,'S'), (5,4,'P'), (5,6,'V'), (6,None,'E'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ancient-viking",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_dict = dict_from_edges(reber_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "loved-breeding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0: [(1, 'B')],\n",
       "             1: [(2, 'T'), (3, 'P')],\n",
       "             2: [(2, 'S'), (4, 'X')],\n",
       "             3: [(3, 'T'), (5, 'V')],\n",
       "             4: [(3, 'X'), (6, 'S')],\n",
       "             5: [(4, 'P'), (6, 'V')],\n",
       "             6: [(None, 'E')]})"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "missing-comfort",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = generate_sentence(node_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "pretty-money",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 1, 'B'),\n",
       " (1, 3, 'P'),\n",
       " (3, 3, 'T'),\n",
       " (3, 5, 'V'),\n",
       " (5, 4, 'P'),\n",
       " (4, 3, 'X'),\n",
       " (3, 5, 'V'),\n",
       " (5, 6, 'V'),\n",
       " (6, None, 'E'))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "verified-petite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BPTVPXVVE'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_from_sentence(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "developmental-labor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PEBTVX'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_letters(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "polish-inflation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PEBTSVX'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_letters(reber_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "empirical-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_edge = sentence[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "operating-messaging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5, 'V')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fantastic-depression",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_sentence_edge = corrupt_edge(sentence_edge, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "empirical-divorce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5, 'B')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupted_sentence_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "stuck-cursor",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_sentence = corrupt_sentence(sentence, reber_edges, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "physical-nation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 1, 'B'),\n",
       " (1, 3, 'P'),\n",
       " (3, 3, 'T'),\n",
       " (3, 5, 'V'),\n",
       " (5, 4, 'P'),\n",
       " (4, 3, 'B'),\n",
       " (3, 5, 'V'),\n",
       " (5, 6, 'T'),\n",
       " (6, None, 'E'))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupted_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-drunk",
   "metadata": {},
   "source": [
    "## Embedder Reber Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "specified-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_reber_edges = ((0,1,'B'), (1,2,'T'), (1,3,'P'), (2,4,reber_edges), (3,5,reber_edges), (4,6, 'T'), (5,6,'P'), (6,None,'E'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "conservative-horse",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_reber_edges = flatten_embedded_edges(embedded_reber_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "democratic-landscape",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 1, 'B'),\n",
       " (1, 2, 'T'),\n",
       " (1, 3, 'P'),\n",
       " (2, '2-1', 'B'),\n",
       " ('2-1', '2-2', 'T'),\n",
       " ('2-1', '2-3', 'P'),\n",
       " ('2-2', '2-2', 'S'),\n",
       " ('2-2', '2-4', 'X'),\n",
       " ('2-3', '2-3', 'T'),\n",
       " ('2-3', '2-5', 'V'),\n",
       " ('2-4', '2-3', 'X'),\n",
       " ('2-4', '2-6', 'S'),\n",
       " ('2-5', '2-4', 'P'),\n",
       " ('2-5', '2-6', 'V'),\n",
       " ('2-6', 4, 'E'),\n",
       " (3, '3-1', 'B'),\n",
       " ('3-1', '3-2', 'T'),\n",
       " ('3-1', '3-3', 'P'),\n",
       " ('3-2', '3-2', 'S'),\n",
       " ('3-2', '3-4', 'X'),\n",
       " ('3-3', '3-3', 'T'),\n",
       " ('3-3', '3-5', 'V'),\n",
       " ('3-4', '3-3', 'X'),\n",
       " ('3-4', '3-6', 'S'),\n",
       " ('3-5', '3-4', 'P'),\n",
       " ('3-5', '3-6', 'V'),\n",
       " ('3-6', 5, 'E'),\n",
       " (4, 6, 'T'),\n",
       " (5, 6, 'P'),\n",
       " (6, None, 'E'))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_reber_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "beautiful-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_dict = dict_from_edges(embedded_reber_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "graduate-sandwich",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0: [(1, 'B')],\n",
       "             1: [(2, 'T'), (3, 'P')],\n",
       "             2: [('2-1', 'B')],\n",
       "             '2-1': [('2-2', 'T'), ('2-3', 'P')],\n",
       "             '2-2': [('2-2', 'S'), ('2-4', 'X')],\n",
       "             '2-3': [('2-3', 'T'), ('2-5', 'V')],\n",
       "             '2-4': [('2-3', 'X'), ('2-6', 'S')],\n",
       "             '2-5': [('2-4', 'P'), ('2-6', 'V')],\n",
       "             '2-6': [(4, 'E')],\n",
       "             3: [('3-1', 'B')],\n",
       "             '3-1': [('3-2', 'T'), ('3-3', 'P')],\n",
       "             '3-2': [('3-2', 'S'), ('3-4', 'X')],\n",
       "             '3-3': [('3-3', 'T'), ('3-5', 'V')],\n",
       "             '3-4': [('3-3', 'X'), ('3-6', 'S')],\n",
       "             '3-5': [('3-4', 'P'), ('3-6', 'V')],\n",
       "             '3-6': [(5, 'E')],\n",
       "             4: [(6, 'T')],\n",
       "             5: [(6, 'P')],\n",
       "             6: [(None, 'E')]})"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "secondary-thomas",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = generate_sentence(node_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "needed-sodium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 1, 'B'),\n",
       " (1, 2, 'T'),\n",
       " (2, '2-1', 'B'),\n",
       " ('2-1', '2-2', 'T'),\n",
       " ('2-2', '2-4', 'X'),\n",
       " ('2-4', '2-3', 'X'),\n",
       " ('2-3', '2-3', 'T'),\n",
       " ('2-3', '2-3', 'T'),\n",
       " ('2-3', '2-5', 'V'),\n",
       " ('2-5', '2-6', 'V'),\n",
       " ('2-6', 4, 'E'),\n",
       " (4, 6, 'T'),\n",
       " (6, None, 'E'))"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "bibliographic-upper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BTBTXXTTVVETE'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_from_sentence(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "important-consideration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 1, 'B'),\n",
       " (1, 2, 'T'),\n",
       " (2, '2-1', 'B'),\n",
       " ('2-1', '2-2', 'S'),\n",
       " ('2-2', '2-4', 'X'),\n",
       " ('2-4', '2-3', 'X'),\n",
       " ('2-3', '2-3', 'T'),\n",
       " ('2-3', '2-3', 'B'),\n",
       " ('2-3', '2-5', 'V'),\n",
       " ('2-5', '2-6', 'V'),\n",
       " ('2-6', 4, 'E'),\n",
       " (4, 6, 'S'),\n",
       " (6, None, 'E'))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupt_sentence(sentence, embedded_reber_edges, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-journal",
   "metadata": {},
   "source": [
    "## Generate Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "quiet-bailey",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_positive = 10000\n",
    "max_corruptions = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-newton",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-huntington",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-thunder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-knife",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-browse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-catalyst",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-roberts",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "expired-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_dict_from_edges(edges):\n",
    "    forward_dict = defaultdict(list)\n",
    "    for (start_node, end_node, letter) in edges:\n",
    "        forward_dict[start_node].append((end_node, letter))\n",
    "    return forward_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dying-brief",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_dict = forward_dict_from_edges(reber_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "framed-example",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0: [(1, 'B')],\n",
       "             1: [(2, 'T'), (3, 'P')],\n",
       "             2: [(2, 'S'), (4, 'X')],\n",
       "             3: [(3, 'T'), (5, 'V')],\n",
       "             4: [(3, 'X'), (6, 'S')],\n",
       "             5: [(4, 'P'), (6, 'V')],\n",
       "             6: [(None, 'E')]})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "consolidated-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(forward_dict):\n",
    "\tsentence = []\n",
    "\tstart_node = 0\n",
    "\twhile start_node is not None:\n",
    "\t\tend_node, letter = choice(forward_dict[start_node])\n",
    "\t\tsentence.append([start_node, end_node, letter])\n",
    "\t\tstart_node = end_node\n",
    "\treturn sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "continuous-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = generate_sentence(forward_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "major-rocket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 'B'],\n",
       " [1, 2, 'T'],\n",
       " [2, 2, 'S'],\n",
       " [2, 4, 'X'],\n",
       " [4, 3, 'X'],\n",
       " [3, 5, 'V'],\n",
       " [5, 4, 'P'],\n",
       " [4, 3, 'X'],\n",
       " [3, 5, 'V'],\n",
       " [5, 6, 'V'],\n",
       " [6, None, 'E']]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "golden-relationship",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_from_sentence(sentence):\n",
    "    return ''.join([edge[-1] for edge in sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "developing-aurora",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BTSXXVPXVVE'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_from_sentence(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dramatic-limitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def letters_from_edges(edges):\n",
    "    return ''.join(set([edge[-1] for edge in edges]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "comic-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = letters_from_edges(reber_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "assumed-sterling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PEBTSVX'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "designed-cooking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt_letter(sentence_edge, edges):\n",
    "    start_node = sentence_edge[0]\n",
    "    possible_nodes = [edge for edge in edges if edge[0] == start_node]\n",
    "    possible_letters = [node[-1] for node in possible_nodes]\n",
    "    all_letters = letters_from_edges(edges)\n",
    "    corruption_letters = list(set(all_letters) - set(possible_letters))\n",
    "    new_letter = choice(corruption_letters)\n",
    "    corrupted_sentence_edge = sentence_edge.copy()\n",
    "    corrupted_sentence_edge[-1] = new_letter\n",
    "    return corrupted_sentence_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "elder-danger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 'B'],\n",
       " [1, 2, 'T'],\n",
       " [2, 2, 'S'],\n",
       " [2, 4, 'X'],\n",
       " [4, 3, 'X'],\n",
       " [3, 5, 'V'],\n",
       " [5, 4, 'P'],\n",
       " [4, 3, 'X'],\n",
       " [3, 5, 'V'],\n",
       " [5, 6, 'V'],\n",
       " [6, None, 'E']]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "former-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_edge = sentence[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "hundred-fourth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 'X']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "appreciated-young",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 'T']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupt_letter(sentence_edge, reber_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "perfect-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt_sentence(sentence, edges, num_corruptions):\n",
    "    assert num_corruptions <= len(sentence)\n",
    "    index_corruptions = sample(range(len(sentence)), num_corruptions)\n",
    "    corrupted_sentence = sentence.copy()\n",
    "    for index in index_corruptions:\n",
    "        corrupted_sentence[index] = corrupt_letter(corrupted_sentence[index], edges)\n",
    "    return corrupted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "secondary-diving",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 'B'],\n",
       " [1, 2, 'T'],\n",
       " [2, 2, 'S'],\n",
       " [2, 4, 'X'],\n",
       " [4, 3, 'X'],\n",
       " [3, 5, 'V'],\n",
       " [5, 4, 'P'],\n",
       " [4, 3, 'X'],\n",
       " [3, 5, 'V'],\n",
       " [5, 6, 'V'],\n",
       " [6, None, 'E']]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "amended-chick",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_corruptions = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dramatic-visitor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 'S'],\n",
       " [1, 2, 'T'],\n",
       " [2, 2, 'S'],\n",
       " [2, 4, 'X'],\n",
       " [4, 3, 'X'],\n",
       " [3, 5, 'B'],\n",
       " [5, 4, 'P'],\n",
       " [4, 3, 'P'],\n",
       " [3, 5, 'V'],\n",
       " [5, 6, 'V'],\n",
       " [6, None, 'E']]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupt_sentence(sentence, reber_edges, num_corruptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-rebate",
   "metadata": {},
   "source": [
    "## Embedded Reber Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "blind-attendance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "criminal-celebration",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_node, end_node, letter = embedded_reber_edges[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "resistant-egypt",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [[str(start_node) + '-' + str(s), str(start_node)+'-'+str(e), l] for s, e, l in letter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "emerging-headline",
   "metadata": {},
   "outputs": [],
   "source": [
    "t[-1][1] = end_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "wireless-supervision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2-0', '2-1', 'B'],\n",
       " ['2-1', '2-2', 'T'],\n",
       " ['2-1', '2-3', 'P'],\n",
       " ['2-2', '2-2', 'S'],\n",
       " ['2-2', '2-4', 'X'],\n",
       " ['2-3', '2-3', 'T'],\n",
       " ['2-3', '2-5', 'V'],\n",
       " ['2-4', '2-3', 'X'],\n",
       " ['2-4', '2-6', 'S'],\n",
       " ['2-5', '2-4', 'P'],\n",
       " ['2-5', '2-6', 'V'],\n",
       " ['2-6', 4, 'E']]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "furnished-malawi",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "polyphonic-immigration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 'B'],\n",
       " [1, 2, 'T'],\n",
       " [1, 3, 'P'],\n",
       " ['2-0', '2-1', 'B'],\n",
       " ['2-1', '2-2', 'T'],\n",
       " ['2-1', '2-3', 'P'],\n",
       " ['2-2', '2-2', 'S'],\n",
       " ['2-2', '2-4', 'X'],\n",
       " ['2-3', '2-3', 'T'],\n",
       " ['2-3', '2-5', 'V'],\n",
       " ['2-4', '2-3', 'X'],\n",
       " ['2-4', '2-6', 'S'],\n",
       " ['2-5', '2-4', 'P'],\n",
       " ['2-5', '2-6', 'V'],\n",
       " ['2-6', 4, 'E'],\n",
       " ['3-0', '3-1', 'B'],\n",
       " ['3-1', '3-2', 'T'],\n",
       " ['3-1', '3-3', 'P'],\n",
       " ['3-2', '3-2', 'S'],\n",
       " ['3-2', '3-4', 'X'],\n",
       " ['3-3', '3-3', 'T'],\n",
       " ['3-3', '3-5', 'V'],\n",
       " ['3-4', '3-3', 'X'],\n",
       " ['3-4', '3-6', 'S'],\n",
       " ['3-5', '3-4', 'P'],\n",
       " ['3-5', '3-6', 'V'],\n",
       " ['3-6', 5, 'E'],\n",
       " [4, 6, 'T'],\n",
       " [5, 6, 'P'],\n",
       " [6, None, 'E']]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-patio",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-reproduction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "present-following",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_dict_from_edges(edges):\n",
    "    forward_dict = defaultdict(list)\n",
    "    for (start_node, end_node, letter) in edges:\n",
    "        if isinstance(letter, tuple):\n",
    "            letter = forward_dict_from_edges(letter)\n",
    "        forward_dict[start_node].append((end_node, letter))\n",
    "    return forward_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bulgarian-bermuda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 1, 'B'),\n",
       " (1, 2, 'T'),\n",
       " (1, 3, 'P'),\n",
       " (2, 2, 'S'),\n",
       " (2, 4, 'X'),\n",
       " (3, 3, 'T'),\n",
       " (3, 5, 'V'),\n",
       " (4, 3, 'X'),\n",
       " (4, 6, 'S'),\n",
       " (5, 4, 'P'),\n",
       " (5, 6, 'V'),\n",
       " (6, None, 'E'))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reber_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "wanted-scholarship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0: [(1, 'B')],\n",
       "             1: [(2, 'T'), (3, 'P')],\n",
       "             2: [(2, 'S'), (4, 'X')],\n",
       "             3: [(3, 'T'), (5, 'V')],\n",
       "             4: [(3, 'X'), (6, 'S')],\n",
       "             5: [(4, 'P'), (6, 'V')],\n",
       "             6: [(None, 'E')]})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_dict_from_edges(reber_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "exotic-intelligence",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_dict = forward_dict_from_edges(embedded_reber_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ancient-poland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0: [(1, 'B')],\n",
       "             1: [(2, 'T'), (3, 'P')],\n",
       "             2: [(4,\n",
       "               defaultdict(list,\n",
       "                           {0: [(1, 'B')],\n",
       "                            1: [(2, 'T'), (3, 'P')],\n",
       "                            2: [(2, 'S'), (4, 'X')],\n",
       "                            3: [(3, 'T'), (5, 'V')],\n",
       "                            4: [(3, 'X'), (6, 'S')],\n",
       "                            5: [(4, 'P'), (6, 'V')],\n",
       "                            6: [(None, 'E')]}))],\n",
       "             3: [(5,\n",
       "               defaultdict(list,\n",
       "                           {0: [(1, 'B')],\n",
       "                            1: [(2, 'T'), (3, 'P')],\n",
       "                            2: [(2, 'S'), (4, 'X')],\n",
       "                            3: [(3, 'T'), (5, 'V')],\n",
       "                            4: [(3, 'X'), (6, 'S')],\n",
       "                            5: [(4, 'P'), (6, 'V')],\n",
       "                            6: [(None, 'E')]}))],\n",
       "             4: [(6, 'T')],\n",
       "             5: [(6, 'P')],\n",
       "             6: [(None, 'E')]})"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "front-estate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(forward_dict):\n",
    "    sentence = []\n",
    "    start_node = 0\n",
    "    while start_node is not None:\n",
    "        end_node, letter = choice(forward_dict[start_node])\n",
    "        if isinstance(letter, defaultdict):\n",
    "            letter = generate_sentence(letter)\n",
    "        sentence.append([start_node, end_node, letter])\n",
    "        start_node = end_node\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "polished-mayor",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = generate_sentence(forward_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "collectible-bible",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_from_sentence(sentence):\n",
    "    letters = []\n",
    "    for edge in sentence:\n",
    "        letter = edge[-1]\n",
    "        if isinstance(letter, list):\n",
    "            letter = string_from_sentence(letter)\n",
    "        letters.append(letter)\n",
    "    return ''.join(letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "atmospheric-texas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BTBPTTVPSETE'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_from_sentence(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-comment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-justice",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-maximum",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-carroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt_letter(sentence_edge, edges):\n",
    "    start_node = sentence_edge[0]\n",
    "    possible_nodes = []\n",
    "    for edge in edges:\n",
    "        \n",
    "    possible_nodes = [edge for edge in edges if edge[0] == start_node]\n",
    "    possible_letters = [node[-1] for node in possible_nodes]\n",
    "    all_letters = letters_from_edges(edges)\n",
    "    corruption_letters = list(set(all_letters) - set(possible_letters))\n",
    "    new_letter = choice(corruption_letters)\n",
    "    corrupted_sentence_edge = sentence_edge.copy()\n",
    "    corrupted_sentence_edge[-1] = new_letter\n",
    "    return corrupted_sentence_edge"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
